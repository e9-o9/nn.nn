â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Z++ Formal Specification: System State                                     â”‚
â”‚                                                                             â”‚
â”‚ This specification formalizes the complete system state of the neural      â”‚
â”‚ network library, including network topology, training state, and global    â”‚
â”‚ invariants that must hold across all operations.                           â”‚
â”‚                                                                             â”‚
â”‚ Depends on: data_model.zpp                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 1: MODULE REGISTRY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ ModuleRegistry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ modules : ModuleIdentifier â‡¸ Module                                         â”‚
â”‚ nextModuleId : ModuleIdentifier                                             â”‚
â”‚                                                                             â”‚
â”‚ dom modules = {0 .. nextModuleId - 1}                                       â”‚
â”‚ âˆ€ mid âˆˆ dom modules â€¢ modules(mid).moduleId = mid                          â”‚
â”‚ nextModuleId = #modules                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  The ModuleRegistry maintains all module instances in the system.
  Invariants ensure:
  - Module IDs are contiguous starting from 0
  - Each module's stored ID matches its registry key
  - nextModuleId equals the total count of modules

â”Œâ”€ RegisterModule â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Î”ModuleRegistry                                                             â”‚
â”‚ m? : Module                                                                 â”‚
â”‚ mid! : ModuleIdentifier                                                     â”‚
â”‚                                                                             â”‚
â”‚ mid! = nextModuleId                                                         â”‚
â”‚ m?.moduleId = mid!                                                          â”‚
â”‚ modules' = modules âˆª {mid! â†¦ m?}                                           â”‚
â”‚ nextModuleId' = nextModuleId + 1                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Registers a new module in the registry, assigning it a unique ID.

â”Œâ”€ UnregisterModule â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Î”ModuleRegistry                                                             â”‚
â”‚ mid? : ModuleIdentifier                                                     â”‚
â”‚                                                                             â”‚
â”‚ mid? âˆˆ dom modules                                                          â”‚
â”‚ modules' = {mid?} â©¤ modules                                                 â”‚
â”‚ nextModuleId' = nextModuleId                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Removes a module from the registry. Note: This may break contiguity
  invariant and should be used carefully, typically only during cleanup.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 2: NETWORK TOPOLOGY STATE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ NetworkTopology â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ rootModule : ModuleIdentifier                                               â”‚
â”‚ registry : ModuleRegistry                                                   â”‚
â”‚ parentChild : ModuleIdentifier â†” ModuleIdentifier                           â”‚
â”‚ depth : ModuleIdentifier â†’ â„•                                                â”‚
â”‚                                                                             â”‚
â”‚ rootModule âˆˆ dom registry.modules                                           â”‚
â”‚ depth(rootModule) = 0                                                       â”‚
â”‚ dom parentChild âŠ† dom registry.modules                                      â”‚
â”‚ ran parentChild âŠ† dom registry.modules                                      â”‚
â”‚ âˆ€ p, c : ModuleIdentifier â€¢ (p, c) âˆˆ parentChild â‡’                         â”‚
â”‚     registry.modules(p).moduleType = Container âˆ§                            â”‚
â”‚     depth(c) = depth(p) + 1                                                 â”‚
â”‚ âˆ€ m : dom depth â€¢ m âˆˆ dom registry.modules                                 â”‚
â”‚ -- Acyclicity: no module is ancestor of itself                             â”‚
â”‚ âˆ€ m : dom registry.modules â€¢ (m, m) âˆ‰ parentChildâº                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  NetworkTopology represents the hierarchical structure of the network:
  - rootModule: Top-level module (typically Sequential or custom network)
  - registry: All modules in the system
  - parentChild: Parent-child relationships (only containers have children)
  - depth: Distance from root (for traversal order)
  
  Invariants ensure:
  - Root module exists in registry at depth 0
  - Only Container modules can be parents
  - Child depth is parent depth + 1
  - No cycles in the module hierarchy (DAG structure)

â”Œâ”€ GetSubModules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÎNetworkTopology                                                            â”‚
â”‚ parent? : ModuleIdentifier                                                  â”‚
â”‚ children! : seq ModuleIdentifier                                            â”‚
â”‚                                                                             â”‚
â”‚ parent? âˆˆ dom registry.modules                                              â”‚
â”‚ registry.modules(parent?).moduleType = Container                            â”‚
â”‚ ran children! = parentChildâŸ¨{parent?}âŸ©                                      â”‚
â”‚ âˆ€ i, j : dom children! â€¢ i < j â‡’ depth(children!(i)) â‰¤ depth(children!(j)) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Retrieves all direct children of a container module, ordered by depth.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 3: TRAINING STATE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ LearningRate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LearningRate == {r : â„ | r > 0}                                             â”‚
â”‚                                                                             â”‚
â”‚ Learning rates must be positive real numbers                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Momentum â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Momentum == {m : â„ | 0 â‰¤ m < 1}                                            â”‚
â”‚                                                                             â”‚
â”‚ Momentum coefficient in range [0, 1)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ OptimizerType â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OptimizerType ::= SGD | Adam | RMSprop | Adagrad                            â”‚
â”‚                                                                             â”‚
â”‚ Types of optimization algorithms supported                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ OptimizerState â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ optimizerType : OptimizerType                                               â”‚
â”‚ learningRate : LearningRate                                                 â”‚
â”‚ momentum : Momentum                                                         â”‚
â”‚ velocities : ParameterName â‡¸ Tensor                                         â”‚
â”‚ iterations : â„•                                                              â”‚
â”‚                                                                             â”‚
â”‚ iterations â‰¥ 0                                                              â”‚
â”‚ -- Velocities exist for all parameters when momentum > 0                   â”‚
â”‚ momentum > 0 â‡’ dom velocities â‰  âˆ…                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  OptimizerState tracks the state of the optimization algorithm:
  - optimizerType: which algorithm is being used
  - learningRate: step size for parameter updates
  - momentum: momentum coefficient for SGD variants
  - velocities: accumulated velocity for momentum-based methods
  - iterations: number of optimization steps performed

â”Œâ”€ DatasetIndex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DatasetIndex == â„•                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ TrainingSample â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ input : Tensor                                                              â”‚
â”‚ target : Tensor                                                             â”‚
â”‚ sampleIndex : DatasetIndex                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  A single training example with input features and target labels.

â”Œâ”€ Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ samples : seq TrainingSample                                                â”‚
â”‚ size : â„•                                                                    â”‚
â”‚                                                                             â”‚
â”‚ size = #samples                                                             â”‚
â”‚ size > 0                                                                    â”‚
â”‚ âˆ€ i : dom samples â€¢ samples(i).sampleIndex = i - 1                         â”‚
â”‚ -- All samples have consistent input shapes                                â”‚
â”‚ âˆ€ i, j : dom samples â€¢ samples(i).input.shape = samples(j).input.shape     â”‚
â”‚ -- All samples have consistent target shapes                               â”‚
â”‚ âˆ€ i, j : dom samples â€¢ samples(i).target.shape = samples(j).target.shape   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Dataset is a collection of training samples with consistency constraints:
  - Non-empty
  - Sample indices are sequential
  - All inputs have the same shape
  - All targets have the same shape

â”Œâ”€ BatchSize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BatchSize == {n : â„• | n > 0}                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Epoch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Epoch == â„•                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ TrainingState â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dataset : Dataset                                                           â”‚
â”‚ batchSize : BatchSize                                                       â”‚
â”‚ currentEpoch : Epoch                                                        â”‚
â”‚ maxEpochs : Epoch                                                           â”‚
â”‚ currentBatch : â„•                                                            â”‚
â”‚ totalBatches : â„•                                                            â”‚
â”‚ optimizer : OptimizerState                                                  â”‚
â”‚ trainingLosses : seq â„                                                      â”‚
â”‚ validationLosses : seq â„                                                    â”‚
â”‚                                                                             â”‚
â”‚ currentEpoch â‰¤ maxEpochs                                                    â”‚
â”‚ maxEpochs > 0                                                               â”‚
â”‚ batchSize â‰¤ dataset.size                                                    â”‚
â”‚ totalBatches = âŒˆdataset.size / batchSizeâŒ‰                                  â”‚
â”‚ currentBatch < totalBatches                                                 â”‚
â”‚ #trainingLosses = currentEpoch Ã— totalBatches + currentBatch                â”‚
â”‚ #validationLosses â‰¤ currentEpoch                                            â”‚
â”‚ âˆ€ loss : ran trainingLosses â€¢ loss â‰¥ 0                                     â”‚
â”‚ âˆ€ loss : ran validationLosses â€¢ loss â‰¥ 0                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  TrainingState captures the complete state of a training session:
  - Dataset and batching configuration
  - Current position in training (epoch, batch)
  - Optimizer state
  - Loss history for monitoring
  
  Invariants ensure:
  - Current epoch doesn't exceed maximum
  - Batch size is reasonable relative to dataset
  - Current batch index is valid
  - Loss history length matches training progress
  - All losses are non-negative

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 4: COMPUTATION STATE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ ForwardCache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ moduleOutputs : ModuleIdentifier â‡¸ Tensor                                   â”‚
â”‚ moduleInputs : ModuleIdentifier â‡¸ Tensor                                    â”‚
â”‚ activations : ModuleIdentifier â‡¸ Tensor                                     â”‚
â”‚                                                                             â”‚
â”‚ dom moduleOutputs = dom moduleInputs                                         â”‚
â”‚ dom activations âŠ† dom moduleOutputs                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ForwardCache stores intermediate results from forward propagation:
  - moduleOutputs: output of each module
  - moduleInputs: input to each module (needed for backward pass)
  - activations: pre-activation values for certain modules
  
  These are needed for gradient computation during backpropagation.

â”Œâ”€ BackwardCache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ moduleGradInputs : ModuleIdentifier â‡¸ Tensor                                â”‚
â”‚ moduleGradOutputs : ModuleIdentifier â‡¸ Tensor                               â”‚
â”‚ parameterGradients : (ModuleIdentifier Ã— ParameterName) â‡¸ Tensor            â”‚
â”‚                                                                             â”‚
â”‚ dom moduleGradInputs = dom moduleGradOutputs                                 â”‚
â”‚ âˆ€ (mid, pname) : dom parameterGradients â€¢                                   â”‚
â”‚     mid âˆˆ dom moduleGradInputs                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  BackwardCache stores gradients computed during backpropagation:
  - moduleGradInputs: gradient with respect to module input
  - moduleGradOutputs: gradient with respect to module output
  - parameterGradients: gradients for all module parameters

â”Œâ”€ ComputationState â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ forwardCache : ForwardCache                                                 â”‚
â”‚ backwardCache : BackwardCache                                               â”‚
â”‚ lastInput : Tensor                                                          â”‚
â”‚ lastOutput : Tensor                                                         â”‚
â”‚ lastLoss : â„                                                                â”‚
â”‚ gradientValid : ğ”¹                                                           â”‚
â”‚                                                                             â”‚
â”‚ lastLoss â‰¥ 0                                                                â”‚
â”‚ gradientValid â‡’ dom backwardCache.moduleGradInputs â‰  âˆ…                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ComputationState tracks the current state of forward and backward passes:
  - Forward and backward caches for intermediate values
  - Last input/output/loss for reference
  - Flag indicating whether gradients are valid (backward has been called)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 5: COMPLETE SYSTEM STATE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ SystemState â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ topology : NetworkTopology                                                  â”‚
â”‚ training : TrainingState                                                    â”‚
â”‚ computation : ComputationState                                              â”‚
â”‚ mode : TrainingMode                                                         â”‚
â”‚                                                                             â”‚
â”‚ -- All modules in topology must be in consistent mode                      â”‚
â”‚ âˆ€ mid âˆˆ dom topology.registry.modules â€¢                                     â”‚
â”‚     topology.registry.modules(mid).mode = mode                               â”‚
â”‚                                                                             â”‚
â”‚ -- Root module output shape matches expected from training data            â”‚
â”‚ computation.lastOutput.shape = training.dataset.samples(1).target.shape     â”‚
â”‚                                                                             â”‚
â”‚ -- If in training mode, gradients must be valid after backward pass        â”‚
â”‚ mode = Training âˆ§ computation.gradientValid â‡’                               â”‚
â”‚     âˆ€ mid âˆˆ dom topology.registry.modules â€¢                                 â”‚
â”‚         mid âˆˆ dom computation.backwardCache.moduleGradInputs                â”‚
â”‚                                                                             â”‚
â”‚ -- Forward cache is consistent with topology                               â”‚
â”‚ dom computation.forwardCache.moduleOutputs âŠ†                                â”‚
â”‚     dom topology.registry.modules                                            â”‚
â”‚                                                                             â”‚
â”‚ -- Backward cache is consistent with topology                              â”‚
â”‚ dom computation.backwardCache.moduleGradInputs âŠ†                            â”‚
â”‚     dom topology.registry.modules                                            â”‚
â”‚                                                                             â”‚
â”‚ -- All parameterized modules have gradients in training mode              â”‚
â”‚ mode = Training âˆ§ computation.gradientValid â‡’                               â”‚
â”‚     âˆ€ mid âˆˆ dom topology.registry.modules â€¢                                 â”‚
â”‚         let m == topology.registry.modules(mid) in                          â”‚
â”‚         dom m.parameters â‰  âˆ… â‡’                                              â”‚
â”‚             âˆ€ pname âˆˆ dom m.parameters â€¢                                     â”‚
â”‚                 (mid, pname) âˆˆ dom computation.backwardCache.parameterGradients â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  SystemState encapsulates the complete state of the neural network system:
  
  1. **Network Structure** (topology): The module hierarchy and relationships
  2. **Training Progress** (training): Dataset, epochs, batches, optimizer
  3. **Computation Cache** (computation): Forward/backward intermediate values
  4. **Execution Mode** (mode): Training vs Evaluation
  
  Global invariants ensure:
  - All modules operate in consistent mode
  - Output shape matches expected target shape
  - In training mode with valid gradients, all modules have computed gradients
  - Caches are consistent with the topology
  - All parameters of all modules have gradients when needed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 6: SYSTEM INITIALIZATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ InitSystemState â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SystemState'                                                                â”‚
â”‚ rootModule? : Module                                                        â”‚
â”‚ trainingData? : Dataset                                                     â”‚
â”‚ batchSize? : BatchSize                                                      â”‚
â”‚ maxEpochs? : Epoch                                                          â”‚
â”‚ learningRate? : LearningRate                                                â”‚
â”‚                                                                             â”‚
â”‚ -- Initialize empty registry and register root module                      â”‚
â”‚ topology'.registry.modules = {0 â†¦ rootModule?}                             â”‚
â”‚ topology'.registry.nextModuleId = 1                                         â”‚
â”‚ topology'.rootModule = 0                                                    â”‚
â”‚ rootModule?.moduleId = 0                                                    â”‚
â”‚                                                                             â”‚
â”‚ -- Initialize topology with just root                                      â”‚
â”‚ topology'.parentChild = âˆ…                                                   â”‚
â”‚ topology'.depth = {0 â†¦ 0}                                                  â”‚
â”‚                                                                             â”‚
â”‚ -- Initialize training state                                               â”‚
â”‚ training'.dataset = trainingData?                                           â”‚
â”‚ training'.batchSize = batchSize?                                            â”‚
â”‚ training'.currentEpoch = 0                                                  â”‚
â”‚ training'.maxEpochs = maxEpochs?                                            â”‚
â”‚ training'.currentBatch = 0                                                  â”‚
â”‚ training'.totalBatches = âŒˆtrainingData?.size / batchSize?âŒ‰                 â”‚
â”‚ training'.optimizer.optimizerType = SGD                                     â”‚
â”‚ training'.optimizer.learningRate = learningRate?                            â”‚
â”‚ training'.optimizer.momentum = 0                                            â”‚
â”‚ training'.optimizer.velocities = âˆ…                                          â”‚
â”‚ training'.optimizer.iterations = 0                                          â”‚
â”‚ training'.trainingLosses = âŸ¨âŸ©                                               â”‚
â”‚ training'.validationLosses = âŸ¨âŸ©                                             â”‚
â”‚                                                                             â”‚
â”‚ -- Initialize computation state                                            â”‚
â”‚ computation'.forwardCache.moduleOutputs = âˆ…                                 â”‚
â”‚ computation'.forwardCache.moduleInputs = âˆ…                                  â”‚
â”‚ computation'.forwardCache.activations = âˆ…                                   â”‚
â”‚ computation'.backwardCache.moduleGradInputs = âˆ…                             â”‚
â”‚ computation'.backwardCache.moduleGradOutputs = âˆ…                            â”‚
â”‚ computation'.backwardCache.parameterGradients = âˆ…                           â”‚
â”‚ computation'.lastLoss = 0                                                   â”‚
â”‚ computation'.gradientValid = false                                          â”‚
â”‚                                                                             â”‚
â”‚ -- Start in training mode                                                  â”‚
â”‚ mode' = Training                                                            â”‚
â”‚ rootModule?.mode = Training                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  InitSystemState creates a new system state with:
  - A root module (typically Sequential or custom network)
  - Training configuration (dataset, batch size, epochs)
  - Initial optimizer state (SGD with specified learning rate)
  - Empty computation caches
  - Training mode active

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 7: MODE TRANSITIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ SetTrainingMode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Î”SystemState                                                                â”‚
â”‚                                                                             â”‚
â”‚ mode' = Training                                                            â”‚
â”‚ âˆ€ mid âˆˆ dom topology.registry.modules â€¢                                     â”‚
â”‚     topology'.registry.modules(mid).mode = Training                         â”‚
â”‚ topology'.registry = topology.registry                                      â”‚
â”‚ topology'.rootModule = topology.rootModule                                  â”‚
â”‚ topology'.parentChild = topology.parentChild                                â”‚
â”‚ topology'.depth = topology.depth                                            â”‚
â”‚ training' = training                                                        â”‚
â”‚ computation' = computation                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Sets all modules to training mode. In training mode:
  - Dropout is active
  - Batch normalization updates running statistics
  - Gradients are computed

â”Œâ”€ SetEvaluationMode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Î”SystemState                                                                â”‚
â”‚                                                                             â”‚
â”‚ mode' = Evaluation                                                          â”‚
â”‚ âˆ€ mid âˆˆ dom topology.registry.modules â€¢                                     â”‚
â”‚     topology'.registry.modules(mid).mode = Evaluation                       â”‚
â”‚ topology'.registry = topology.registry                                      â”‚
â”‚ topology'.rootModule = topology.rootModule                                  â”‚
â”‚ topology'.parentChild = topology.parentChild                                â”‚
â”‚ topology'.depth = topology.depth                                            â”‚
â”‚ training' = training                                                        â”‚
â”‚ computation' = computation                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Sets all modules to evaluation mode. In evaluation mode:
  - Dropout is inactive (pass-through)
  - Batch normalization uses running statistics
  - Gradients are not computed (optimization)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 8: SYSTEM STATE QUERIES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ GetAllParameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÎSystemState                                                                â”‚
â”‚ params! : seq Parameter                                                     â”‚
â”‚                                                                             â”‚
â”‚ params! = [p : Parameter |                                                  â”‚
â”‚            âˆƒ mid : dom topology.registry.modules,                           â”‚
â”‚              pname : dom topology.registry.modules(mid).parameters â€¢        â”‚
â”‚              p = topology.registry.modules(mid).parameters(pname)]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Retrieves all parameters from all modules in the network.

â”Œâ”€ GetTotalParameterCount â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÎSystemState                                                                â”‚
â”‚ count! : â„•                                                                  â”‚
â”‚                                                                             â”‚
â”‚ count! = Î£ [mid : dom topology.registry.modules |                          â”‚
â”‚              Î£ [p : ran topology.registry.modules(mid).parameters |         â”‚
â”‚                  âˆ(p.value.shape)]]                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Computes total number of learnable parameters across all modules.

â”Œâ”€ GetTrainingProgress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÎSystemState                                                                â”‚
â”‚ progress! : â„                                                               â”‚
â”‚                                                                             â”‚
â”‚ progress! = (training.currentEpoch Ã— training.totalBatches +                â”‚
â”‚              training.currentBatch) /                                       â”‚
â”‚             (training.maxEpochs Ã— training.totalBatches)                    â”‚
â”‚ 0 â‰¤ progress! â‰¤ 1                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Computes training progress as a fraction in [0, 1].

â”Œâ”€ IsTrainingComplete â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÎSystemState                                                                â”‚
â”‚ complete! : ğ”¹                                                               â”‚
â”‚                                                                             â”‚
â”‚ complete! â‡” (training.currentEpoch = training.maxEpochs âˆ§                  â”‚
â”‚              training.currentBatch = training.totalBatches - 1)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Checks if training has completed all epochs.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 9: SYSTEM STATE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This specification defines the complete system state of the neural network
library, including:

1. **Module Registry**: Central repository of all module instances with unique
   identifiers and registration/unregistration operations.

2. **Network Topology**: Hierarchical structure of modules with parent-child
   relationships, ensuring DAG structure and proper depth tracking.

3. **Training State**: Complete training configuration and progress tracking,
   including dataset, batching, epochs, optimizer state, and loss history.

4. **Computation State**: Caches for forward and backward propagation,
   storing intermediate values needed for gradient computation.

5. **System State**: Top-level state combining all components with global
   invariants ensuring consistency across:
   - Module modes (Training/Evaluation)
   - Shape compatibility
   - Gradient completeness
   - Cache consistency

6. **State Initialization**: Operation to create a new system state with
   proper initial conditions.

7. **Mode Transitions**: Operations to switch between training and evaluation
   modes, affecting all modules uniformly.

8. **State Queries**: Read-only operations to inspect system state without
   modification.

The global invariants in SystemState ensure that the entire system remains
in a consistent, valid state across all operations defined in operations.zpp.
